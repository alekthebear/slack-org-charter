# 20251026 Project Update
* Latest results file: [Link](20251025_predicted.md)
* Error Analysis Output: [Link](errors.json) 
* Model reasoning traces
    * User Role traces: [Link](./normalized_user_roles.json)
    * User Manager traces: [Link](normalized_user_managers.json)

## High-Level Design
The initial directions I thought of to approach this problem were:
1. **ML Approach with LLMs**: extract features from the dataset but, instead of choosing an traditional ML model and encoding features according, use the LLM as a model and encode features into the prompt.
2. **Agentic Approach**: run an agent with tools and memory. Similar to how Claude Code can iterate through the code base to answer questions.

Ultimately went with the first approach since:
* Given the (somewhat ambiguous) deadline and the expected amount of work, I was more confident to produce some results with the first approach.
* I tried the second approach by prompting Claude Code directly, but it was quite ineffective. I think it's possible to build an agent to answer general questions, but it would take significant work and iteration. 
* With such a specific problem, its easier if I (the human) act as the agent and directly use my human intuition to investigate instead of trying to encode intuitions into a general slack data scientist.

## Features
Brief summaried list of the features I've tried, separated into "Used" and "Unused" sections.
### Used
* User Metadata: Titles, active status, last_message_time... etc.
* User Channel Activity: user's message count per channel (both recent and historic).
* Web Search: Asking a model with web search capability to get the public listing of employees and their roles. Useful for exec level roles.
* Channel Conventions: Sought patterns and semantic meaning in the company's slack channels (e.g. `team-*`, `proj-*`). Useful for determining user's role and activity in combination with channel activity.
* Explicit Manager Messages: Go through all the recent messages where the report structure is explicitly stated (`#access-request`). Strongest signal for reporting structure, but may not be generally applicable across different organizations.
* Mention Graph: the number of recent mentions between employees. Only seemed to have a minor effect.
### Unused
* Linkedin Search: This is legally ambiguous and the scraper requires private login. Seems to get some signals but decided its not worth the trouble.
* Channel Labels: Attempted to get detailed description and activity analysis for each channel. However, the v0 attempt of this feature did not have much impact over just using channel names.
* Welcome Messages: States the role of the employee. Did not improve performance and actaully confused the model when historical data was used.
* Shared Channels Between Users: redundant with User Channel Activity
* Team Modeling: Idea was to define the teams within the company, then figure out the leads/members of each team and use that as a signal to build org chart. However, after some preliminary work I decided to shelve this as it would be quite involved (many different pieces)

## Results Evaluation
There were three main sources of errors
1. **Active Employees**: ground truth had 41 employees
   * Precision (87%): classified 47 employees, so 6 extra employees as active
   * Recall (100%): Captured all 41 ground truth employees
2. **Working On**: 
   * Qualitatively speaking the prediction outputs produced seemed fairly decent, albeit not matching the ground truth 100%. 
   * Skipped quantitative analysis (decided to focus more on the more critical issue of organiziational structure)
3. **Management Hierarchy**: 
   * Accuracy (75.6%) obtained by comparing the relationships "Person A is managed by Person B".

### Management Hierarchy Error Analysis
Management hierarchies we got wrong:

| full_name             | pred             | actual    | reason                                                                            |
|----------------------|------------------|-----------|-----------------------------------------------------------------------------------|
| Vic                  | Kumail Jaffer    | Phillip   | CTO assumption                                                                    |
| Evangeline           | Kumail Jaffer    | Phillip   | CTO assumption                                                                    |
| Karen                | Ashley Kalley    | Evangeline| mapping issue (We actually got Karen Ying right but Karen Duran was included incorrectly) |
| Gianluca             | Kumail Jaffer    | Aaron     | explicit manager signal                                                           |
| Dave Orr             | Aaron Cohen      | Vic       | explicit manager signal                                                           |
| Chandler             | Johnny Dallas    | Vic       | explicit manager signal                                                           |
| Austin (PT contractor)| Evangeline Cheng| Aaron     | team mismatch                                                                     |
| Steven               | Evangeline Cheng | Aaron     | team mismatch                                                                     |
| Ashley               | Clint            | Jinen     | team mismatch                                                                     |
| Andy                 | Evangeline Cheng | Vic       | team mismatch                                                                     |

---
Going over the error types:

#### 1. CTO Assumption
* **Issue**: The model decides that high level engineering managers should go under the CTO. For this dataset, they actually go directly under the CEO. 
* **Sample model reasoning**:
> Victor is acting as an engineering manager (rick and Jordan Maduro explicitly report to him). Platform engineers (e.g., Gianluca Esposito) explicitly report to the CTO, and Grapevine is CTO\u2011led. Title/discipline alignment and strong communication with Kumail make the CTO, Kumail Jaffer, the most likely manager.
* **Possible Solutions**: 
    * Easy solution is to modify the manager inference prompt with something like `"high level engineering managers are likely to report to the CEO rather than the CTO"`. I tried this and it worked. The accuracy went to 80.5%.
    * Ultimately decided against it because that is not generalizable. Org-structured vary widely (some CTOs manage a lot, others don't)
    * Another solution might be to examine the conversation threads for ambiguous cases, but that is out-of-scope for now.

#### 2. Incorrect Explicit Manager Signals
* **Issue**: We extract relationships from the posts where managerial relationships are expressed with very high confidence (basically the `#access-request` channel). The signal can sometimes have false positives, most likely because chain-of-command changes and the signal is out of date.
* **Sample model reasoning**:
> Explicit manager signal indicates David Orr reports to Aaron Cohen (2025-09-24). Titles and project alignment (AV/Meeting Recording) corroborate.
* **Possible Solutions**: 
    * Possibly have the model weigh the recency of the explicit signal against recent actual activity.
    * Ultimately did not tweak this for now as the TP far outweighs the FP.

#### 3. Team/Activity Misaligned with Management Chain
* **Issue**: The recent activity of the employee indicates a stronger work alignment with one group instead of another
* **Sample model reasoning**: (Steven Yau -> Evangeline Cheng)
> Steven is a Core App v2 engineer in the Payments pod. Explicit signals show multiple Payments/Core App engineers (David Rios, ryan kauk, Emily Hu, Alex Budure, giorgi) report to Evangeline Cheng, indicating she manages this group. Mention patterns between Steven and Evangeline are consistent with a manager-report relationship.
* **Possible Solutions**: Requires deeper analysis. Model is determining teams based on channel clusters, but certain pod teams may be a conglomerations of people from different teams (e.g. infra engineers, product engineers, designers). The model has been able to separate the broader roles but struggles with substructures with the engineering org.

## Notable Challenges
1. **Dynamic nature of organizations**: people leave, teams shift, managers change. It is quite impossible to capture all these simply through slack messages since the distribution shift would take awhile to propagate (e.g. Jingsong Wang has left recently so most of the historical data still reflects the structure when he was around)
2. **Single Source Dataset**: I am basically overfitting the model to a single organization. The only counterbalance against overfitting is my own common sense. I'd love to run this against another slack archive but it's hard to find data sources like this.

## Other Topics
* Scalability of solution: LLM context, cost would be the major issues
* Claude Code: tried Claude Code in a few ways to varying degrees of success
    1. Problem solve from scratch: not great. Also kept trying to hack the metrics even when prompted not to do so.
    2. Claude Code as a Search Agent: Wanted to Claude to use existing tools/code to dig through messages. Promising but no real results.
    3. Claude Code as a feature generator: did not magically improve performance but gave a lot of good ideas.





